{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip show azureml-explain-model azureml-interpret"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azureml-explain-model\r\nVersion: 1.48.0\r\nSummary: The package has been deprecated and might not receive future updates.\r\nHome-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\nAuthor: Microsoft Corp\r\nAuthor-email: None\r\nLicense: https://aka.ms/azureml-sdk-license\r\nLocation: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\r\nRequires: azureml-interpret\r\nRequired-by: \r\n---\r\nName: azureml-interpret\r\nVersion: 1.48.0\r\nSummary: Machine Learning interpret package is used to interpret ML models\r\nHome-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\nAuthor: Microsoft Corp\r\nAuthor-email: None\r\nLicense: https://aka.ms/azureml-sdk-license\r\nLocation: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\r\nRequires: numpy, interpret-community, numba, azureml-core, shap\r\nRequired-by: azureml-train-automl-runtime, azureml-responsibleai, azureml-explain-model\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1675431750137
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "\r\n",
        "# load the churn dataset\r\n",
        "print(\"Loading Data...\")\r\n",
        "data = pd.read_csv('data/telco-csv.csv')\r\n",
        "\r\n",
        "# create a copy\r\n",
        "churn = data.copy()\r\n",
        "\r\n",
        "# drop those colume have null values\r\n",
        "churn = churn.drop(['loglong','logtoll','logequi','logcard','logwire','lninc'],axis = 1)\r\n",
        "\r\n",
        "# convert categorical to num\r\n",
        "for x in churn.columns:\r\n",
        "    if churn[x].dtypes == 'object':\r\n",
        "        churn[x] = pd.Categorical(data[x]).codes\r\n",
        "churn.head()\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "features = ['region', 'tenure', 'age', 'marital', 'address', 'income', 'ed',\r\n",
        "       'employ', 'retire', 'gender', 'reside', 'tollfree', 'equip', 'callcard',\r\n",
        "       'wireless', 'longmon', 'tollmon', 'equipmon', 'cardmon', 'wiremon',\r\n",
        "       'longten', 'tollten', 'equipten', 'cardten', 'wireten', 'multline',\r\n",
        "       'voice', 'pager', 'internet', 'callid', 'callwait', 'forward', 'confer',\r\n",
        "       'ebill',\r\n",
        "       'custcat']\r\n",
        "labels = ['not-churn', 'churn']\r\n",
        "X, y = churn[features].values, churn['churn'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\r\n",
        "\r\n",
        "# Train a decision tree model\r\n",
        "print('Training a decision tree model')\r\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy:', acc)\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "print('AUC: ' + str(auc))\r\n",
        "\r\n",
        "print('Model trained.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Loading Data...\nTraining a decision tree model\nAccuracy: 0.65\nAUC: 0.5722913178665392\nModel trained.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675432198720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from interpret.ext.blackbox import TabularExplainer\r\n",
        "\r\n",
        "# \"features\" and \"classes\" fields are optional\r\n",
        "tab_explainer = TabularExplainer(model,\r\n",
        "                             X_train, \r\n",
        "                             features=features, \r\n",
        "                             classes=labels)\r\n",
        "print(tab_explainer, \"ready!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "TabularExplainer ready!\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675432316680
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can use the training data or the test data here(global)\r\n",
        "global_tab_explanation = tab_explainer.explain_global(X_train)\r\n",
        "\r\n",
        "# Get the top features by importance\r\n",
        "global_tab_feature_importance = global_tab_explanation.get_feature_importance_dict()\r\n",
        "for feature, importance in global_tab_feature_importance.items():\r\n",
        "    print(feature,\":\", importance)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "longten : 0.16034149715220142\nequipten : 0.06448847731111285\nequip : 0.05616902146624003\nlongmon : 0.04734919078399353\nregion : 0.04076351879687003\ncallcard : 0.039629152951262174\nage : 0.03852103160131641\nemploy : 0.0323102231493754\ntollmon : 0.026504871613724616\nequipmon : 0.02551737692785027\naddress : 0.023619595550495576\nwiremon : 0.02359603806343496\nincome : 0.023023066867985144\ncustcat : 0.02180416447424759\ncallid : 0.019837337576229516\ncardten : 0.019329064289708618\ninternet : 0.01885969884418004\ntollten : 0.018536839024908304\ntenure : 0.017556632608931366\ned : 0.015474893437487916\nconfer : 0.009777950665846786\ncallwait : 0.009072596641836007\nwireten : 0.008888407267985413\ncardmon : 0.007295355308270335\npager : 0.006712934135668149\nwireless : 0.006694489313310983\nmultline : 0.0031371111008208345\nmarital : 0.0023783535801189795\nvoice : 0.0019038673224118566\nreside : 0.0016643553143474946\ntollfree : 0.0\ngender : 0.0\nretire : 0.0\nforward : 0.0\nebill : 0.0\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675432399402
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the observations we want to explain (the first two)(local)\r\n",
        "X_explain = X_test[0:2]\r\n",
        "\r\n",
        "# Get predictions\r\n",
        "predictions = model.predict(X_explain)\r\n",
        "\r\n",
        "# Get local explanations\r\n",
        "local_tab_explanation = tab_explainer.explain_local(X_explain)\r\n",
        "\r\n",
        "# Get feature names and importance for each possible label\r\n",
        "local_tab_features = local_tab_explanation.get_ranked_local_names()\r\n",
        "local_tab_importance = local_tab_explanation.get_ranked_local_values()\r\n",
        "\r\n",
        "for l in range(len(local_tab_features)):\r\n",
        "    print('Support for', labels[l])\r\n",
        "    label = local_tab_features[l]\r\n",
        "    for o in range(len(label)):\r\n",
        "        print(\"\\tObservation\", o + 1)\r\n",
        "        feature_list = label[o]\r\n",
        "        total_support = 0\r\n",
        "        for f in range(len(feature_list)):\r\n",
        "            print(\"\\t\\t\", feature_list[f], ':', local_tab_importance[l][o][f])\r\n",
        "            total_support += local_tab_importance[l][o][f]\r\n",
        "        print(\"\\t\\t ----------\\n\\t\\t Total:\", total_support, \"Prediction:\", labels[predictions[o]])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Support for not-churn\n\tObservation 1\n\t\t longten : 0.10184878175735787\n\t\t callid : 0.042536997055290376\n\t\t age : 0.04075932103857574\n\t\t equip : 0.03673256193804056\n\t\t callcard : 0.034648238299235794\n\t\t equipten : 0.02802349721802188\n\t\t callwait : 0.0246454128562706\n\t\t ed : 0.014885309164208205\n\t\t tollten : 0.011499946975097734\n\t\t tenure : 0.00905429430538997\n\t\t cardten : 0.008605370856808042\n\t\t address : 0.007333074279688879\n\t\t region : 0.006777344108855881\n\t\t internet : 0.006592581147760534\n\t\t income : 0.00467056358857096\n\t\t pager : 0.004313291285295525\n\t\t cardmon : 0.003078764280724516\n\t\t wireten : 0.001108619751540068\n\t\t wiremon : 0.0010322222549905037\n\t\t marital : 0.0006709750566893424\n\t\t voice : 0.0004098350038112456\n\t\t ebill : 0.0\n\t\t tollfree : 0.0\n\t\t gender : 0.0\n\t\t retire : 0.0\n\t\t forward : 0.0\n\t\t reside : -0.0003300032802366781\n\t\t wireless : -0.0013477531135199128\n\t\t confer : -0.002049401640470432\n\t\t tollmon : -0.0031414458336518885\n\t\t employ : -0.003790257335827738\n\t\t multline : -0.003934168235746679\n\t\t equipmon : -0.0068164069323005195\n\t\t longmon : -0.0383038957007847\n\t\t custcat : -0.0437993844353997\n\t\t ----------\n\t\t Total: 0.28571428571428603 Prediction: not-churn\n\tObservation 2\n\t\t equip : 0.22790081756606084\n\t\t internet : 0.07232355626203561\n\t\t age : 0.03583734537336552\n\t\t region : 0.025611082054405602\n\t\t callwait : 0.023937791435932693\n\t\t tenure : 0.023565248395938966\n\t\t equipten : 0.017558919142709663\n\t\t multline : 0.006033396544389436\n\t\t wireten : 0.005384620490337558\n\t\t tollten : 0.00538221009544536\n\t\t longmon : 0.004850464563475189\n\t\t ed : 0.0024885300515172315\n\t\t voice : 0.002366035521860352\n\t\t employ : 0.0017826693461752657\n\t\t cardmon : 0.0014619309262166396\n\t\t pager : 0.00026202626319533516\n\t\t tollfree : 0.0\n\t\t ebill : 0.0\n\t\t forward : 0.0\n\t\t retire : 0.0\n\t\t gender : 0.0\n\t\t reside : -0.000208006279434851\n\t\t confer : -0.002476707515525545\n\t\t wireless : -0.0029738170858493993\n\t\t marital : -0.0035165873502476805\n\t\t cardten : -0.003842307589658273\n\t\t income : -0.00651603729227138\n\t\t address : -0.007421255905669301\n\t\t wiremon : -0.00783010213310691\n\t\t tollmon : -0.010863637683065037\n\t\t longten : -0.011458244948215554\n\t\t callid : -0.016562169513504713\n\t\t equipmon : -0.017791664117138305\n\t\t callcard : -0.027329226406799263\n\t\t custcat : -0.05224259449828913\n\t\t ----------\n\t\t Total: 0.2857142857142862 Prediction: not-churn\nSupport for churn\n\tObservation 1\n\t\t custcat : 0.0437993844353997\n\t\t longmon : 0.038303895700784685\n\t\t equipmon : 0.006816406932300515\n\t\t multline : 0.003934168235746679\n\t\t employ : 0.0037902573358277467\n\t\t tollmon : 0.003141445833651878\n\t\t confer : 0.0020494016404704316\n\t\t wireless : 0.0013477531135199128\n\t\t reside : 0.0003300032802366784\n\t\t ebill : 0.0\n\t\t retire : 0.0\n\t\t gender : 0.0\n\t\t tollfree : 0.0\n\t\t forward : 0.0\n\t\t voice : -0.00040983500381124537\n\t\t marital : -0.0006709750566893423\n\t\t wiremon : -0.0010322222549904933\n\t\t wireten : -0.0011086197515400693\n\t\t cardmon : -0.0030787642807245195\n\t\t pager : -0.004313291285295515\n\t\t income : -0.004670563588570968\n\t\t internet : -0.006592581147760526\n\t\t region : -0.006777344108855869\n\t\t address : -0.007333074279688875\n\t\t cardten : -0.00860537085680804\n\t\t tenure : -0.009054294305389968\n\t\t tollten : -0.011499946975097736\n\t\t ed : -0.014885309164208193\n\t\t callwait : -0.02464541285627061\n\t\t equipten : -0.028023497218021852\n\t\t callcard : -0.034648238299235815\n\t\t equip : -0.036732561938040545\n\t\t age : -0.040759321038575685\n\t\t callid : -0.04253699705529031\n\t\t longten : -0.10184878175735801\n\t\t ----------\n\t\t Total: -0.285714285714286 Prediction: not-churn\n\tObservation 2\n\t\t custcat : 0.05224259449828913\n\t\t callcard : 0.027329226406799266\n\t\t equipmon : 0.017791664117138284\n\t\t callid : 0.016562169513504733\n\t\t longten : 0.011458244948215315\n\t\t tollmon : 0.010863637683064982\n\t\t wiremon : 0.007830102133106889\n\t\t address : 0.007421255905669306\n\t\t income : 0.006516037292271393\n\t\t cardten : 0.0038423075896582746\n\t\t marital : 0.0035165873502476814\n\t\t wireless : 0.0029738170858493976\n\t\t confer : 0.0024767075155255427\n\t\t reside : 0.00020800627943485105\n\t\t forward : 0.0\n\t\t gender : 0.0\n\t\t retire : 0.0\n\t\t tollfree : 0.0\n\t\t ebill : 0.0\n\t\t pager : -0.0002620262631953345\n\t\t cardmon : -0.0014619309262166413\n\t\t employ : -0.0017826693461752727\n\t\t voice : -0.0023660355218603525\n\t\t ed : -0.0024885300515172333\n\t\t longmon : -0.004850464563475236\n\t\t tollten : -0.005382210095445359\n\t\t wireten : -0.005384620490337557\n\t\t multline : -0.006033396544389435\n\t\t equipten : -0.01755891914270967\n\t\t tenure : -0.023565248395938973\n\t\t callwait : -0.023937791435932693\n\t\t region : -0.025611082054405626\n\t\t age : -0.03583734537336545\n\t\t internet : -0.07232355626203557\n\t\t equip : -0.22790081756606065\n\t\t ----------\n\t\t Total: -0.285714285714286 Prediction: not-churn\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675432508611
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.48.0 to work with project\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675432627902
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\r\n",
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "# Create a folder for the experiment files\r\n",
        "experiment_folder = 'churn_train_and_explain'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "# Copy the data file into the experiment folder\r\n",
        "shutil.copy('data/telco-csv.csv', os.path.join(experiment_folder, \"telco-csv.csv\"))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "'churn_train_and_explain/telco-csv.csv'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675432682793
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/churn_training.py\r\n",
        "# Import libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "\r\n",
        "# Import Azure ML run library\r\n",
        "from azureml.core.run import Run\r\n",
        "\r\n",
        "# Import libraries for model explanation\r\n",
        "from azureml.interpret import ExplanationClient\r\n",
        "from interpret.ext.blackbox import TabularExplainer\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the diabetes dataset\r\n",
        "print(\"Loading Data...\")\r\n",
        "data = pd.read_csv('telco-csv.csv')\r\n",
        "\r\n",
        "# create a copy\r\n",
        "churn = data.copy()\r\n",
        "\r\n",
        "# drop those colume have null values\r\n",
        "churn = churn.drop(['loglong','logtoll','logequi','logcard','logwire','lninc'],axis = 1)\r\n",
        "\r\n",
        "# convert categorical to num\r\n",
        "for x in churn.columns:\r\n",
        "    if churn[x].dtypes == 'object':\r\n",
        "        churn[x] = pd.Categorical(data[x]).codes\r\n",
        "churn.head()\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "features = ['region', 'tenure', 'age', 'marital', 'address', 'income', 'ed',\r\n",
        "       'employ', 'retire', 'gender', 'reside', 'tollfree', 'equip', 'callcard',\r\n",
        "       'wireless', 'longmon', 'tollmon', 'equipmon', 'cardmon', 'wiremon',\r\n",
        "       'longten', 'tollten', 'equipten', 'cardten', 'wireten', 'multline',\r\n",
        "       'voice', 'pager', 'internet', 'callid', 'callwait', 'forward', 'confer',\r\n",
        "       'ebill',\r\n",
        "       'custcat']\r\n",
        "labels = ['not-churn', 'churn']\r\n",
        "X, y = churn[features].values, churn['churn'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\r\n",
        "\r\n",
        "# Train a decision tree model\r\n",
        "print('Training a decision tree model')\r\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "run.log('Accuracy', np.float(acc))\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "run.log('AUC', np.float(auc))\r\n",
        "\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\r\n",
        "joblib.dump(value=model, filename='outputs/churn.pkl')\r\n",
        "\r\n",
        "# Get explanation\r\n",
        "explainer = TabularExplainer(model, X_train, features=features, classes=labels)\r\n",
        "explanation = explainer.explain_global(X_test)\r\n",
        "\r\n",
        "# Get an Explanation Client and upload the explanation\r\n",
        "explain_client = ExplanationClient.from_run(run)\r\n",
        "explain_client.upload_model_explanation(explanation, comment='Tabular Explanation')\r\n",
        "\r\n",
        "# Complete the run\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing churn_train_and_explain/churn_training.py\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/interpret_env.yml\r\n",
        "name: batch_environment\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- pandas\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults\r\n",
        "  - azureml-interpret"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing churn_train_and_explain/interpret_env.yml\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\r\n",
        "from azureml.core.runconfig import DockerConfiguration\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "\r\n",
        "# Create a Python environment for the experiment\r\n",
        "explain_env = Environment.from_conda_specification(\"explain_env\", experiment_folder + \"/interpret_env.yml\")\r\n",
        "\r\n",
        "# Create a script config\r\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\r\n",
        "                      script='churn_training.py',\r\n",
        "                      environment=explain_env,\r\n",
        "                      docker_runtime_config=DockerConfiguration(use_docker=True)) \r\n",
        "\r\n",
        "# submit the experiment\r\n",
        "experiment_name = 'mslearn-churn-explain'\r\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\r\n",
        "run = experiment.submit(config=script_config)\r\n",
        "RunDetails(run).show()\r\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d9709c4cfaa46958f7e6212de85b896"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Starting\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-churn-explain_1675433082_31eac33e?wsid=/subscriptions/bd5c51d3-de0b-41fc-99f7-375e6737efda/resourcegroups/project_dp100/workspaces/project&tid=474565c1-bca4-4295-a2f5-b0c7dbf2591c\", \"run_id\": \"mslearn-churn-explain_1675433082_31eac33e\", \"run_properties\": {\"run_id\": \"mslearn-churn-explain_1675433082_31eac33e\", \"created_utc\": \"2023-02-03T14:04:44.338051Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"c3c9e55a-f933-4397-a4b1-394a2323b84c\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Starting\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"1:34:54\", \"run_number\": \"1675433084\", \"run_queued_details\": {\"status\": \"Starting\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.48.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m run \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39msubmit(config\u001b[38;5;241m=\u001b[39mscript_config)\n\u001b[1;32m     19\u001b[0m RunDetails(run)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py:869\u001b[0m, in \u001b[0;36mRun.wait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    867\u001b[0m poll_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m current_status \u001b[38;5;129;01min\u001b[39;00m running_states:\n\u001b[0;32m--> 869\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_before_polling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpoll_start_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     current_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_status()\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;66;03m# add unknown status as running status\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675433599920
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.interpret import ExplanationClient\r\n",
        "\r\n",
        "# Get the feature explanations\r\n",
        "client = ExplanationClient.from_run(run)\r\n",
        "engineered_explanations = client.download_model_explanation()\r\n",
        "feature_importances = engineered_explanations.get_feature_importance_dict()\r\n",
        "\r\n",
        "# Overall feature importance\r\n",
        "print('Feature\\tImportance')\r\n",
        "for key, value in feature_importances.items():\r\n",
        "    print(key, '\\t', value)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}