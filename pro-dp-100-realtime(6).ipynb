{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.48.0 to work with project\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1675441953465
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.core import Model\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "\r\n",
        "# Create an Azure ML experiment in your workspace\r\n",
        "experiment = Experiment(workspace=ws, name=\"mslearn-train-churn\")\r\n",
        "run = experiment.start_logging()\r\n",
        "print(\"Starting experiment:\", experiment.name)\r\n",
        "\r\n",
        "# load the chrun dataset\r\n",
        "print(\"Loading Data...\")\r\n",
        "churn = pd.read_csv('data/telco-csv.csv')\r\n",
        "\r\n",
        "churn2 = churn.copy()\r\n",
        "\r\n",
        "# drop those colume have null values\r\n",
        "churn2 = churn2.drop(['loglong','logtoll','logequi','logcard','logwire','lninc'],axis = 1)\r\n",
        "\r\n",
        "# convert categorical to num\r\n",
        "for x in churn2.columns:\r\n",
        "    if churn2[x].dtypes == 'object':\r\n",
        "        churn2[x] = pd.Categorical(churn[x]).codes\r\n",
        "        \r\n",
        "# Separate features and labels\r\n",
        "X, y = churn2[['region', 'tenure', 'age', 'marital', 'address', 'income', 'ed',\r\n",
        "       'employ', 'retire', 'gender', 'reside', 'tollfree', 'equip', 'callcard',\r\n",
        "       'wireless', 'longmon', 'tollmon', 'equipmon', 'cardmon', 'wiremon',\r\n",
        "       'longten', 'tollten', 'equipten', 'cardten', 'wireten', 'multline',\r\n",
        "       'voice', 'pager', 'internet', 'callid', 'callwait', 'forward', 'confer',\r\n",
        "       'ebill',\r\n",
        "       'custcat']].values, churn2['churn'].values\r\n",
        "\r\n",
        "# Split data into training set and test set\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\r\n",
        "\r\n",
        "# Train a decision tree model\r\n",
        "print('Training a decision tree model')\r\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy:', acc)\r\n",
        "run.log('Accuracy', np.float(acc))\r\n",
        "\r\n",
        "# calculate AUC\r\n",
        "y_scores = model.predict_proba(X_test)\r\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\r\n",
        "print('AUC: ' + str(auc))\r\n",
        "run.log('AUC', np.float(auc))\r\n",
        "\r\n",
        "# Save the trained model\r\n",
        "model_file = 'chrun_model.pkl'\r\n",
        "joblib.dump(value=model, filename=model_file)\r\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\r\n",
        "\r\n",
        "# Complete the run\r\n",
        "run.complete()\r\n",
        "\r\n",
        "# Register the model\r\n",
        "run.register_model(model_path='outputs/chrun_model.pkl', model_name='chrun_model',\r\n",
        "                   tags={'Training context':'Inline Training'},\r\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\r\n",
        "\r\n",
        "print('Model trained and registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting experiment: mslearn-train-churn\nLoading Data...\nTraining a decision tree model\nAccuracy: 0.6633333333333333\nAUC: 0.5806878306878307\nModel trained and registered.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675442283794
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "for model in Model.list(ws):\r\n",
        "    print(model.name, 'version:', model.version)\r\n",
        "    for tag_name in model.tags:\r\n",
        "        tag = model.tags[tag_name]\r\n",
        "        print ('\\t',tag_name, ':', tag)\r\n",
        "    for prop_name in model.properties:\r\n",
        "        prop = model.properties[prop_name]\r\n",
        "        print ('\\t',prop_name, ':', prop)\r\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "chrun_model version: 1\n\t Training context : Inline Training\n\t AUC : 0.5806878306878307\n\t Accuracy : 0.6633333333333333\n\n\nchurn_classifier version: 1\n\n\nchurn_model version: 1\n\t Training context : Pipeline\n\t AUC : 0.5969863668978714\n\t Accuracy : 0.6666666666666666\n\n\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675442291457
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ws.models['churn_model']\r\n",
        "print(model.name, 'version', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "churn_model version 1\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675442333826
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "# Create a folder for the deployment files\r\n",
        "deployment_folder = './churn_service'\r\n",
        "os.makedirs(deployment_folder, exist_ok=True)\r\n",
        "print(deployment_folder, 'folder created.')\r\n",
        "\r\n",
        "# Set path for scoring script\r\n",
        "script_file = 'score_churn.py'\r\n",
        "script_path = os.path.join(deployment_folder,script_file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "./churn_service folder created.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675442379736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_path\r\n",
        "import json\r\n",
        "import joblib\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "# Called when the service is loaded\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Get the path to the deployed model file and load it\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'churn_model.pkl')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "# Called when a request is received\r\n",
        "def run(raw_data):\r\n",
        "    # Get the input data as a numpy array\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "    # Get a prediction from the model\r\n",
        "    predictions = model.predict(data)\r\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\r\n",
        "    classnames = ['not-churn', 'churn']\r\n",
        "    predicted_classes = []\r\n",
        "    for prediction in predictions:\r\n",
        "        predicted_classes.append(classnames[prediction])\r\n",
        "    # Return the predictions as JSON\r\n",
        "    return json.dumps(predicted_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing ./churn_service/score_churn.py\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "# Configure the scoring environment\r\n",
        "service_env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\r\n",
        "service_env.inferencing_stack_version=\"latest\"\r\n",
        "\r\n",
        "inference_config = InferenceConfig(source_directory=deployment_folder,\r\n",
        "                                   entry_script=script_file,\r\n",
        "                                   environment=service_env)\r\n",
        "\r\n",
        "# Configure the web service container\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "\r\n",
        "# Deploy the model as a service\r\n",
        "print('Deploying model...')\r\n",
        "service_name = \"churn-service\"\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Deploying model...\nTips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-02-03 16:42:02+00:00 Creating Container Registry if not exists.\n2023-02-03 16:42:02+00:00 Registering the environment.\n2023-02-03 16:42:04+00:00 Use the existing image.\n2023-02-03 16:42:05+00:00 Submitting deployment to compute.\n2023-02-03 16:42:11+00:00 Checking the status of deployment churn-service..\n2023-02-03 16:44:26+00:00 Checking the status of inference endpoint churn-service.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675442772496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "# This time our input is an array of two feature arrays\r\n",
        "x_new = [0,45,30,1,0,63,2,4,1,1,4,1,1,1,1,7.1,40.75,39.75,16.5,50.85,314.8,1849.5,1717.2,775,2239.65,1,1,1,1,1,1,1,1,1,2]\r\n",
        "\r\n",
        "# Convert the array or arrays to a serializable list in a JSON document\r\n",
        "input_json = json.dumps({\"data\": x_new})\r\n",
        "\r\n",
        "# Call the web service, passing the input data\r\n",
        "predictions = service.run(input_data = input_json)\r\n",
        "\r\n",
        "# Get the predicted classes.\r\n",
        "predicted_classes = json.loads(predictions)\r\n",
        "   \r\n",
        "print(predicted_classes[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\nResponse Code: 502\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '616', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Fri, 03 Feb 2023 16:56:38 GMT', 'Server': 'nginx', 'X-Ms-Client-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Run-Function-Failed': 'True', 'X-Ms-Server-Version': 'azmlinfsrv/0.7.6', 'X-Request-Id': 'b8ac2afc-b42b-41cb-9bac-5eca7e0e6f23'}\nContent: b'Expected 2D array, got 1D array instead:\\narray=[0.00000e+00 4.50000e+01 3.00000e+01 1.00000e+00 0.00000e+00 6.30000e+01\\n 2.00000e+00 4.00000e+00 1.00000e+00 1.00000e+00 4.00000e+00 1.00000e+00\\n 1.00000e+00 1.00000e+00 1.00000e+00 7.10000e+00 4.07500e+01 3.97500e+01\\n 1.65000e+01 5.08500e+01 3.14800e+02 1.84950e+03 1.71720e+03 7.75000e+02\\n 2.23965e+03 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\\n 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 2.00000e+00].\\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.'\n\n"
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\nResponse Code: 502\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '616', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Fri, 03 Feb 2023 16:56:38 GMT', 'Server': 'nginx', 'X-Ms-Client-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Run-Function-Failed': 'True', 'X-Ms-Server-Version': 'azmlinfsrv/0.7.6', 'X-Request-Id': 'b8ac2afc-b42b-41cb-9bac-5eca7e0e6f23'}\nContent: b'Expected 2D array, got 1D array instead:\\narray=[0.00000e+00 4.50000e+01 3.00000e+01 1.00000e+00 0.00000e+00 6.30000e+01\\n 2.00000e+00 4.00000e+00 1.00000e+00 1.00000e+00 4.00000e+00 1.00000e+00\\n 1.00000e+00 1.00000e+00 1.00000e+00 7.10000e+00 4.07500e+01 3.97500e+01\\n 1.65000e+01 5.08500e+01 3.14800e+02 1.84950e+03 1.71720e+03 7.75000e+02\\n 2.23965e+03 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\\n 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 2.00000e+00].\\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\\nResponse Code: 502\\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '616', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Fri, 03 Feb 2023 16:56:38 GMT', 'Server': 'nginx', 'X-Ms-Client-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Run-Function-Failed': 'True', 'X-Ms-Server-Version': 'azmlinfsrv/0.7.6', 'X-Request-Id': 'b8ac2afc-b42b-41cb-9bac-5eca7e0e6f23'}\\nContent: b'Expected 2D array, got 1D array instead:\\\\narray=[0.00000e+00 4.50000e+01 3.00000e+01 1.00000e+00 0.00000e+00 6.30000e+01\\\\n 2.00000e+00 4.00000e+00 1.00000e+00 1.00000e+00 4.00000e+00 1.00000e+00\\\\n 1.00000e+00 1.00000e+00 1.00000e+00 7.10000e+00 4.07500e+01 3.97500e+01\\\\n 1.65000e+01 5.08500e+01 3.14800e+02 1.84950e+03 1.71720e+03 7.75000e+02\\\\n 2.23965e+03 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\\\\n 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 2.00000e+00].\\\\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.'\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m input_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_new})\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Call the web service, passing the input data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Get the predicted classes.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(predictions)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/aci.py:400\u001b[0m, in \u001b[0;36mAciWebservice.run\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WebserviceException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived bad response from service. More information can be found by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    401\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`.get_logs()` on the webservice object.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    402\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponse Code: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    403\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeaders: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    404\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(resp\u001b[38;5;241m.\u001b[39mstatus_code, resp\u001b[38;5;241m.\u001b[39mheaders, resp\u001b[38;5;241m.\u001b[39mcontent),\n\u001b[1;32m    405\u001b[0m                               logger\u001b[38;5;241m=\u001b[39mmodule_logger)\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\nResponse Code: 502\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '616', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Fri, 03 Feb 2023 16:56:38 GMT', 'Server': 'nginx', 'X-Ms-Client-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Run-Function-Failed': 'True', 'X-Ms-Server-Version': 'azmlinfsrv/0.7.6', 'X-Request-Id': 'b8ac2afc-b42b-41cb-9bac-5eca7e0e6f23'}\nContent: b'Expected 2D array, got 1D array instead:\\narray=[0.00000e+00 4.50000e+01 3.00000e+01 1.00000e+00 0.00000e+00 6.30000e+01\\n 2.00000e+00 4.00000e+00 1.00000e+00 1.00000e+00 4.00000e+00 1.00000e+00\\n 1.00000e+00 1.00000e+00 1.00000e+00 7.10000e+00 4.07500e+01 3.97500e+01\\n 1.65000e+01 5.08500e+01 3.14800e+02 1.84950e+03 1.71720e+03 7.75000e+02\\n 2.23965e+03 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\\n 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 2.00000e+00].\\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\\nResponse Code: 502\\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '616', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Fri, 03 Feb 2023 16:56:38 GMT', 'Server': 'nginx', 'X-Ms-Client-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Request-Id': '5499ae70-37b3-448c-9a3c-97e9d39c74f5', 'X-Ms-Run-Function-Failed': 'True', 'X-Ms-Server-Version': 'azmlinfsrv/0.7.6', 'X-Request-Id': 'b8ac2afc-b42b-41cb-9bac-5eca7e0e6f23'}\\nContent: b'Expected 2D array, got 1D array instead:\\\\narray=[0.00000e+00 4.50000e+01 3.00000e+01 1.00000e+00 0.00000e+00 6.30000e+01\\\\n 2.00000e+00 4.00000e+00 1.00000e+00 1.00000e+00 4.00000e+00 1.00000e+00\\\\n 1.00000e+00 1.00000e+00 1.00000e+00 7.10000e+00 4.07500e+01 3.97500e+01\\\\n 1.65000e+01 5.08500e+01 3.14800e+02 1.84950e+03 1.71720e+03 7.75000e+02\\\\n 2.23965e+03 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00\\\\n 1.00000e+00 1.00000e+00 1.00000e+00 1.00000e+00 2.00000e+00].\\\\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.'\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675443398569
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}